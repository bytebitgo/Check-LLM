import os
import streamlit as st
import asyncio
from components.model_selector import model_selector, model_parameters
from services import LLMServiceFactory
from services.base import Message
from services.openai_service import OpenAIService
from services.azure_openai_service import AzureOpenAIService
from services.anthropic_service import AnthropicService

def check_service_config(service_name: str) -> bool:
    """æ£€æŸ¥æœåŠ¡é…ç½®æ˜¯å¦å®Œæ•´"""
    if service_name == "OpenAI":
        return bool(os.getenv("OPENAI_API_KEY"))
    elif service_name == "Azure OpenAI":
        return all([
            os.getenv("AZURE_OPENAI_API_KEY"),
            os.getenv("AZURE_OPENAI_ENDPOINT"),
            os.getenv("AZURE_DEPLOYMENT_NAME")
        ])
    elif service_name == "Anthropic":
        return bool(os.getenv("ANTHROPIC_API_KEY"))
    return False

async def get_service_provider():
    """è·å–æœåŠ¡æä¾›å•†"""
    providers = {
        "OpenAI": OpenAIService,
        "Azure OpenAI": AzureOpenAIService,
        "Anthropic": AnthropicService
    }
    
    # è·å–å·²é…ç½®çš„æœåŠ¡æä¾›å•†
    available_providers = {
        name: cls for name, cls in providers.items()
        if check_service_config(name)
    }
    
    if not available_providers:
        st.error("æœªæ‰¾åˆ°ä»»ä½•å¯ç”¨çš„æœåŠ¡æä¾›å•†ï¼Œè¯·å…ˆåœ¨é…ç½®ç®¡ç†é¡µé¢è®¾ç½®ç›¸å…³APIå¯†é’¥")
        return None, None
    
    # é€‰æ‹©æœåŠ¡æä¾›å•†
    provider_name = st.selectbox(
        "é€‰æ‹©æœåŠ¡æä¾›å•†",
        options=list(available_providers.keys())
    )
    
    if not provider_name:
        return None, None
    
    # å®ä¾‹åŒ–æœåŠ¡
    try:
        service = available_providers[provider_name]()
        models = await service.get_available_models()
        
        if not models:
            st.error(f"{provider_name} æœªè·å–åˆ°å¯ç”¨æ¨¡å‹ï¼Œè¯·æ£€æŸ¥é…ç½®æ˜¯å¦æ­£ç¡®")
            return None, None
        
        model = st.selectbox("é€‰æ‹©æ¨¡å‹", options=models)
        return service, model
        
    except Exception as e:
        st.error(f"åˆå§‹åŒ– {provider_name} æœåŠ¡å¤±è´¥: {str(e)}")
        return None, None

async def chat_page():
    """èŠå¤©é¡µé¢"""
    st.title("æ¨¡å‹å¯¹è¯æµ‹è¯•")
    
    try:
        # åˆå§‹åŒ–session state
        if "messages" not in st.session_state:
            st.session_state.messages = []
        if "performance_records" not in st.session_state:
            st.session_state.performance_records = []
        
        # ä¾§è¾¹æ é…ç½®
        with st.sidebar:
            st.header("æ¨¡å‹é…ç½®")
            provider, model = await get_service_provider()
            
            if not provider or not model:
                return
            
            # æ¸…ç©ºèŠå¤©æŒ‰é’®
            if st.button("æ¸…ç©ºèŠå¤©è®°å½•", type="secondary"):
                st.session_state.messages = []
                st.session_state.performance_records = []  # åŒæ—¶æ¸…ç©ºæ€§èƒ½è®°å½•
                st.rerun()
        
        # æ˜¾ç¤ºèŠå¤©å†å²
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])
        
        # ç”¨æˆ·è¾“å…¥
        if prompt := st.chat_input():
            # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
            st.session_state.messages.append({
                "role": "user",
                "content": prompt
            })
            
            with st.chat_message("user"):
                st.markdown(prompt)
            
            # è°ƒç”¨API
            with st.chat_message("assistant"):
                message_placeholder = st.empty()
                stats_placeholder = st.empty()
                full_response = ""
                
                try:
                    message_placeholder.markdown("ğŸ¤” æ€è€ƒä¸­...")
                    
                    # è·å–æµå¼å“åº”
                    response_generator = await provider.chat_completion(
                        messages=[
                            {"role": msg["role"], "content": msg["content"]}
                            for msg in st.session_state.messages
                        ],
                        model=model,
                        stream=True
                    )
                    
                    # å¤„ç†æµå¼å“åº”
                    async for chunk in response_generator:
                        if chunk["type"] == "content":
                            full_response += chunk["content"]
                            message_placeholder.markdown(full_response + "â–Œ")
                        elif chunk["type"] == "stats":
                            # æ˜¾ç¤ºæœ€ç»ˆå“åº”ï¼ˆä¸å¸¦å…‰æ ‡ï¼‰
                            message_placeholder.markdown(full_response)
                            
                            # æ·»åŠ åŠ©æ‰‹æ¶ˆæ¯åˆ°å†å²è®°å½•
                            st.session_state.messages.append({
                                "role": "assistant",
                                "content": full_response
                            })
                            
                            # è·å–æ¨¡å‹ä¿¡æ¯ä»¥è®¡ç®—æˆæœ¬
                            model_info = await provider.get_model_info(model)
                            
                            if model_info and model_info.pricing:
                                # è®¡ç®—æˆæœ¬
                                prompt_cost = (
                                    model_info.pricing["input"] *
                                    chunk["stats"]["prompt_tokens"] / 1000
                                )
                                completion_cost = (
                                    model_info.pricing["output"] *
                                    chunk["stats"]["completion_tokens"] / 1000
                                )
                                total_cost = prompt_cost + completion_cost
                                
                                # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                                stats_placeholder.caption(
                                    f"å“åº”æ—¶é—´: {chunk['stats']['response_time']:.2f}ç§’ | "
                                    f"è¾“å…¥tokens: {chunk['stats']['prompt_tokens']} | "
                                    f"è¾“å‡ºtokens: {chunk['stats']['completion_tokens']} | "
                                    f"æ€»tokens: {chunk['stats']['total_tokens']} | "
                                    f"æˆæœ¬: ${total_cost:.4f}"
                                )
                                
                                # æ·»åŠ æ€§èƒ½è®°å½•
                                performance_record = {
                                    "provider": provider.__class__.__name__,
                                    "model": model,
                                    "response_time": chunk["stats"]["response_time"],
                                    "prompt_tokens": chunk["stats"]["prompt_tokens"],
                                    "completion_tokens": chunk["stats"]["completion_tokens"],
                                    "total_tokens": chunk["stats"]["total_tokens"],
                                    "cost": total_cost
                                }
                                
                                if "performance_records" not in st.session_state:
                                    st.session_state.performance_records = []
                                st.session_state.performance_records.append(performance_record)
                    
                    # æ£€æŸ¥æ˜¯å¦æœ‰å“åº”
                    if not full_response:
                        message_placeholder.error("æ¨¡å‹æ²¡æœ‰ç”Ÿæˆä»»ä½•å“åº”")
                        if st.session_state.messages:
                            st.session_state.messages.pop()  # ç§»é™¤ç”¨æˆ·æ¶ˆæ¯
                        return
                    
                except Exception as e:
                    error_msg = str(e)
                    if "æœªæ”¶åˆ°æ¨¡å‹å“åº”" in error_msg:
                        message_placeholder.error("æ¨¡å‹æ²¡æœ‰ç”Ÿæˆå“åº”ï¼Œè¯·é‡è¯•")
                    else:
                        message_placeholder.error(f"ç”Ÿæˆå“åº”æ—¶å‡ºé”™: {error_msg}")
                    
                    # ç§»é™¤ç”¨æˆ·æ¶ˆæ¯ï¼ˆä»…åœ¨å®Œå…¨å¤±è´¥æ—¶ï¼‰
                    if not full_response and st.session_state.messages:
                        st.session_state.messages.pop()
                
    except Exception as e:
        st.error(f"é¡µé¢åŠ è½½å‡ºé”™: {str(e)}") 